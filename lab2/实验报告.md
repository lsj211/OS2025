# 一、First-Fit 连续物理内存分配（`default_pmm.c` 中相关函数解析）



## 概览 — 数据结构与关键域

* **free_area_t free_area**：记录空闲块链表（`free_list`）和空闲页总数 `nr_free`。
* **struct Page**（每个物理页对应一个 `struct Page`）：

  * `flags`：状态位（如 `PG_reserved`、`PG_property` 等）。
  * `property`：如果该页是一个空闲块的起始页，则记录该连续空闲块的页数；否则通常为 0。
  * `ref`：引用计数（空闲页应为 0）。
  * `page_link`：把 `Page` 插入到 `free_list` 的链表节点。
* **链表 API（list.h）**：`list_init`、`list_add`、`list_add_before`、`list_del`、`list_next`、`list_prev` 等，用来维护按物理地址从低到高的空闲块链表。
* **辅助宏/函数**：

  * `le2page(le, page_link)`：从链表节点得到 `struct Page *`。
  * `SetPageProperty(p)` / `ClearPageProperty(p)`：设置/清除 `PG_property` 标志。
  * `PageReserved(p)`、`PageProperty(p)`：判断标志位。
  * `set_page_ref(p, v)`：设置 `ref`。

---

## `default_init`：初始化 free area

```c
static void default_init(void) {
    list_init(&free_list);
    nr_free = 0;
}
```

**作用**：

* 初始化空闲链表为空，并把空闲页计数 `nr_free` 清为 0。
* 为后续把内存块插入 `free_list` 做准备。

---

## `default_init_memmap(base, n)`：把一段物理页范围作为“一个空闲块”加入管理

主要流程（对应代码）：

1. `assert(n > 0)`。
2. 遍历 `base` 到 `base + n - 1`，对每个 `Page`：

   * `assert(PageReserved(p))`（内核在早期会把这些页标为 reserved，表示页面分配表可操作）。
   * 清除 `flags` 与 `property`，`set_page_ref(p, 0)`。
3. 在 `base`（起始页）处设置 `base->property = n`，并 `SetPageProperty(base)`，表示这是一个大小为 `n` 的空闲块起始页。
4. `nr_free += n`。
5. 将 `base` 的 `page_link` 插入 `free_list`，并且**维持链表按物理地址从低到高顺序**（代码中通过遍历找到第一个 `page` 大于 `base` 的位置插入，或尾部追加）。

**要点**：

* 每个空闲块只在其起始页上保留 `property` 字段，链表节点也只使用空闲块起始页的 `page_link`。
* 在内存初始化时会多次调用此函数，把系统内的所有可用内存段逐一插入到 `free_list`。

---

## `default_alloc_pages(n)`：按 First-Fit 分配连续 `n` 页

主要流程：

1. 检查 `n > 0`，若 `n > nr_free` 则直接返回 `NULL`（不够页）。
2. 顺序遍历 `free_list`（从链表头开始，物理地址由低到高）寻找第一个 `p` 满足 `p->property >= n`（First-Fit 策略）。
3. 找到后：

   * 从链表中 `list_del(&p->page_link)` 将此块移出（因为要修改它）。
   * 若 `p->property > n`（块大于请求）：

     * 在 `p + n`（起始地址向后偏 `n` 页的位置）设置新的空闲块 `q`：`q->property = p->property - n; SetPageProperty(q)`。
     * 把 `q` 的链表节点插回原来的链表位置（代码用 `prev = list_prev(&p->page_link)` 保存位置再 `list_add(prev, &q->page_link)`，保持地址顺序）。
   * 对于被分配的 **起始 n 页**：

     * 把它们标记为已保留：`PG_reserved = 1`（或等价地清除 `PG_property` 并保持 `reserved`），并 `ClearPageProperty(page)`（因不再是空闲块起点）。
     * `nr_free -= n`。
4. 返回被分配块的起始 `struct Page *`（如果未找到合适块则返回 `NULL`）。

**关键点**：

* **First-Fit**：找到第一个能满足的空闲块并在该位置分配（优点：遍历结束早；缺点：会产生低地址处很多小碎片）。
* **分裂逻辑**：若空闲块大于请求，则把剩余部分作为新的空闲块插回链表（并设置其 `property`）。
* 被分配的页 **不保留 `property` 字段**（只有空闲块起始页才有 `property`）。

---

## `default_free_pages(base, n)`：释放连续 `n` 页并尝试合并

主要流程：

1. 校验 `n > 0`。
2. 对 `[base, base + n - 1]` 的每一页：

   * `assert(!PageReserved(p) && !PageProperty(p))`（这里代码断言页不是 reserved 且不是空闲起始页 —— 注意：有的实现中释放前这些页可能处于 reserved 状态，具体断言依实现而定；你给出的实现先清 `flags` 并 `set_page_ref(p, 0)`）。
   * 清 `flags`，`set_page_ref(p, 0)`。
3. 在 `base` 上设置 `base->property = n`，并 `SetPageProperty(base)`，把该释放块视作新的空闲块起点。
4. `nr_free += n`。
5. 把 `base` 插入 `free_list`，**插入位置按物理地址升序**（遍历找到第一个 `page` 大于 `base` 的位置插入）。
6. **尝试向低地址方向合并**：

   * 找到 `base` 在链表中的前驱 `le = list_prev(&base->page_link)`（若不是链表头），取其对应 `p`。
   * 如果 `p + p->property == base`（前驱空闲块和当前紧邻），则把 `p->property += base->property`，移除 `base` 的 `page_link`，并把 `base` 清除 `PG_property`（因为 `base` 不再是块起点）；再把 `base = p`（合并后新起点成为 `p`）。
7. **尝试向高地址方向合并**（与当前 `base`）：

   * 找到 `le = list_next(&base->page_link)`，若不是尾部则 `q = le2page(le, page_link)`。
   * 如果 `base + base->property == q`（紧邻），则把 `base->property += q->property`，`ClearPageProperty(q)`，并 `list_del(&q->page_link)`（把 `q` 的节点移除，因为合并成 `base`）。
8. 最终结果：释放块可能被合并为更大的空闲块，从而减少碎片。

**注意点**：

* 插入时维持链表地址顺序对合并操作至关重要 —— 只有这样前驱/后继才是物理邻居。
* 合并操作要同时维护 `property` 与链表节点（删除被合并块的链表节点）。
* `nr_free` 要在释放时增加（分配时减少），以便快速判断是否有足够页可分配。

---

## `default_nr_free_pages` 与自检（`basic_check` / `default_check`）

* `default_nr_free_pages`：返回 `nr_free`，用于外部统计当前空闲页数。
* `basic_check` / `default_check`：一组测试函数，用来验证分配/释放/合并逻辑是否正确。`default_check` 会在多种分配/释放顺序下断言链表性态与 `nr_free` 的正确性，这是保证实现正确性的单元测试。

---

## 示例

假设 `free_list` 初始有两个空闲块：

* A: 起始页 0，size 3 （pages 0..2）
* B: 起始页 10，size 5（pages 10..14）
  链表按地址顺序： A -> B

1. `alloc_pages(2)`（First-Fit）：

   * 遍历到 A（size 3），满足 `>=2`，在 A 起始位置分配 pages 0..1 返回。
   * 剩余 `A'` 变为起始页 `page 2`，size = 1，插回链表。
   * `free_list` 现在： `A' (page2,size1) -> B`
2. `free_pages(base=page0, n=2)`（释放刚才分配的 2 页）：

   * 把 pages 0..1 标为 free，创建空闲块起点 `page0` size 2，插入链表（地址顺序）。
   * 插入后链表临时为： `page0(size2) -> page2(size1) -> B`
   * 向低地址合并：前驱为空（page0 为首）——无合并。
   * 向高地址合并：`page0 + 2 == page2` 成立，所以合并后 `page0->property = 3`，删除 `page2` 的链表节点。
   * 最后链表恢复为 `A (page0,size3) -> B`（与初始相同）。

---

# 二、Best-Fit 物理内存管理器设计文档

## 1. 概述

### 1.1 设计目标
Best-Fit 物理内存管理器是一种基于页框的内存分配策略，其核心目标是通过选择最适合请求大小的空闲块来最小化内存碎片。本实现参考了 First-Fit 算法的基础架构，并对核心分配逻辑进行修改，以实现更优的内存利用率。

### 1.2 核心特性
- 以页为单位管理物理内存
- 采用最佳适配策略分配内存块
- 支持内存块的合并操作，减少外部碎片
- 维护空闲页块的有序链表，提高分配效率
- 兼容 First-Fit 算法的基础数据结构和接口

## 2. 架构设计

### 2.1 数据结构
Best-Fit 算法复用了 First-Fit 算法的核心数据结构：

```c
// 空闲页块链表
static list_entry_t free_list;
// 空闲页总数
static unsigned int nr_free;
```

每个物理页框由 `struct Page` 表示，其中关键字段包括：
- `property`：表示连续空闲页的数量（仅对块首有效）
- `page_link`：用于将页块连接到空闲链表的节点
- `flags`：包含页框状态标记（如是否为空闲块首）

### 2.2 与 First-Fit 的架构差异
Best-Fit 与 First-Fit 共享相同的整体架构，包括：
- 相同的初始化流程
- 相同的内存释放和合并逻辑
- 相同的空闲链表维护方式

主要差异体现在内存分配阶段的块选择策略上。

## 3. 核心算法

### 3.1 初始化算法 (`best_fit_init`)

```c
static void best_fit_init(void) {
    list_init(&free_list);
    nr_free = 0;
}
```

初始化过程与 First-Fit 完全相同，均是初始化空闲链表并将空闲页计数清零。

### 3.2 内存映射初始化 (`best_fit_init_memmap`)

该函数负责初始化物理内存页框，与 First-Fit 实现完全一致：

1. 重置每个页框的标志和引用计数
2. 标记连续页块的首页并设置块大小
3. 将新的空闲块按地址升序插入空闲链表

关键代码实现：
```c
// 按地址升序插入空闲块
if (base < page) {
    list_add_before(le, &(base->page_link));
    break;
} else if (list_next(le) == &free_list) {
    list_add(le, &(base->page_link));
}
```

### 3.3 内存分配算法 (`best_fit_alloc_pages`)

这是 Best-Fit 与 First-Fit 算法的核心差异点。

First-Fit 策略：
- 遍历空闲链表，返回第一个能满足大小的块
- 时间复杂度：O(n)，但通常找到第一个满足条件的块就停止

Best-Fit 策略：
- 遍历整个空闲链表，寻找能满足大小且最小的块
- 时间复杂度：O(n)，但总是需要遍历整个链表

实现代码对比：

**First-Fit 分配逻辑：**
```c
while ((le = list_next(le)) != &free_list) {
    struct Page *p = le2page(le, page_link);
    if (p->property >= n) {
        page = p;
        break;  // 找到第一个满足条件的块就返回
    }
}
```

**Best-Fit 分配逻辑：**
```c
size_t min_size = nr_free + 1;  // 初始化一个大于最大可能值的大小
while ((le = list_next(le)) != &free_list) {
    struct Page *p = le2page(le, page_link);
    // 寻找满足需求且最小的块
    if (p->property >= n && p->property < min_size) {
        min_size = p->property;
        page = p;
    }
}
```

找到最佳块后，两者的块拆分和链表维护逻辑相同：
```c
if (page != NULL) {
    list_entry_t* prev = list_prev(&(page->page_link));
    list_del(&(page->page_link));
    if (page->property > n) {  // 块拆分
        struct Page *p = page + n;
        p->property = page->property - n;
        SetPageProperty(p);
        list_add(prev, &(p->page_link));
    }
    nr_free -= n;
    ClearPageProperty(page);
}
```

### 3.4 内存释放算法 (`best_fit_free_pages`)

内存释放算法与 First-Fit 完全相同，主要包括：

1. 重置待释放页框的状态
2. 按地址顺序将释放的块插入空闲链表
3. 尝试与前向和后向的空闲块合并，减少外部碎片

合并逻辑：
```c
// 与前向块合并
if (p + p->property == base) {
    p->property += base->property;
    ClearPageProperty(base);
    list_del(&(base->page_link));
    base = p;
}

// 与后向块合并
if (base + base->property == p) {
    base->property += p->property;
    ClearPageProperty(p);
    list_del(&(p->page_link));
}
```

### 3.5 辅助函数

- `best_fit_nr_free_pages`：返回空闲页总数，与 First-Fit 实现相同
- `basic_check` 和 `best_fit_check`：用于验证内存管理器的正确性，其中检查逻辑针对 Best-Fit 特性进行了调整

## 4. 与 First-Fit 算法的对比分析

| 特性 | First-Fit | Best-Fit |
|------|-----------|----------|
| 分配策略 | 选择第一个足够大的块 | 选择最小的足够大的块 |
| 遍历范围 | 通常无需遍历整个链表 | 必须遍历整个链表 |
| 内存碎片 | 可能产生较多大碎片 | 碎片较小且分布均匀 |
| 分配速度 | 通常较快 | 相对较慢 |
| 适用场景 | 频繁分配大块内存 | 分配大小多变的场景 |

## 5. 测试验证

### 5.1 功能测试

`best_fit_check` 函数专门验证了 Best-Fit 算法的核心特性：

```c
// 测试最佳适配特性
free_pages(p0 + 1, 2);
free_pages(p0 + 4, 1);
assert((p1 = alloc_pages(1)) != NULL);
assert(alloc_pages(2) != NULL);  // 验证优先选择最合适的块
assert(p0 + 4 == p1);  // 确认分配了最小的可用块
```

### 5.2 测试结果

Best-Fit 算法通过所有基础测试，并在特定场景下表现出更优的内存利用率：
- 能够正确处理连续内存块的分配与释放
- 合并逻辑能有效减少外部碎片
- 在大小混合的分配模式下表现更优

## 6. 总结

Best-Fit 物理内存管理器在 First-Fit 算法的基础架构上，通过修改核心的块选择策略，实现了更优的内存利用率。其主要设计思路是：

1. 复用 First-Fit 的数据结构和链表维护逻辑
2. 更改分配阶段的块选择算法，遍历所有空闲块以找到最佳匹配
3. 保持与 First-Fit 相同的释放和合并逻辑，确保内存块的连续性

这种实现方式既利用了现有代码的稳定性，又通过策略调整获得了更好的内存管理效果，特别适合内存分配大小多变的场景。



# 三、buddy_pmm 内存分配器设计与测试文档

## 1. 概述

### 1.1 设计目标
buddy_pmm 是一种高效的页级内存分配器，专门用于管理物理内存页的分配与回收。它通过将内存块以2的幂次方大小进行划分和合并，实现低碎片、高效率的内存管理。

### 1.2 核心特性
- **块大小为2的幂**：所有可分配块大小均为2的幂，简化分裂与合并逻辑
- **低外部碎片**：通过伙伴块合并机制减少内存碎片
- **快速分配回收**：利用完全二叉树结构实现O(log n)时间复杂度操作
- **连续物理内存**：保证分配的内存块物理地址连续
- **自动块合并**：释放时自动与相邻伙伴块合并为更大块

## 2. 架构设计

### 2.1 核心架构

#### 内存管理结构
```c
// buddy_pmm核心数据结构
typedef struct {
    unsigned size;                    // 可管理的总页数（为2的幂）
    unsigned* longest;                // 二叉树数组，记录每节点最大连续空闲块大小
    struct Page* reserve_page;        // 预留页起始地址（存放longest数组）
    struct Page* first_page;          // 可被分配的第一页地址
    unsigned reserve_count;           // 预留页数量
} buddy_t;
```

**核心组件**：
- **管理页集**：被管理的物理页集合，总大小为2的幂
- **二叉树结构**：记录各节点最大空闲块大小的完全二叉树
- **预留页**：存储二叉树数据结构的物理页

### 2.2 数据结构关系

```
buddy_t (buddy_pmm核心)
├── size = 总管理页数（2^n）
├── longest[] = 二叉树数组（大小为2*size-1）
│   ├── 根节点 (index=0) → 最大空闲块大小
│   ├── 中间节点 → 子树最大空闲块
│   └── 叶子节点 → 单个页或已分配块
├── reserve_page → 存储longest数组的物理页
└── first_page → 可分配内存的起始页

完全二叉树结构
┌─────────────┐
│   根节点     │  size=8
├──────┬──────┤
│左子树│右子树 │  size=4
├─┬─┬──┴─┬─┬──┤
│ │ │    │ │  │  size=2
├┬┴┬┴──┬┴┬┴┴──┤
││ │ │  ││ │ │ │  size=1
┴┴─┴─┴──┴┴─┴─┴─┘
```

## 3. 核心算法

### 3.1 初始化算法 (`buddy_init_memmap`)

```c
// 1. 计算存储二叉树所需预留页数
size_t tree_bytes = (2 * n - 1) * sizeof(unsigned);
size_t reserve_page_cnt = (tree_bytes + PGSIZE - 1) / PGSIZE;

// 2. 调整可管理页数为2的幂
size_t total_free_pages = n - reserve_page_cnt;
if (!is_power_of_2(total_free_pages))
    total_free_pages = prev_power_of_2(total_free_pages);

// 3. 初始化二叉树结构
buddy.longest = (unsigned*)buddy.reserve_page;
init_longest(buddy.longest, buddy.size);
```

**关键步骤**：
- 预留物理页存储二叉树结构
- 调整可管理内存大小为2的幂
- 初始化二叉树各节点值，叶子节点为1，父节点为子节点之和

### 3.2 内存分配算法 (`buddy_alloc_pages`)

```c
// 1. 计算最小分配块大小（2的幂）
size_t node_size = 1;
while (node_size < n) {
    node_size <<= 1;
}

// 2. 自顶向下搜索合适块
int index = 0;
size_t level_size = buddy.size;
size_t offset = 0;

while (level_size != node_size) {
    level_size >>= 1;
    int left = left_leaf(index);
    int right = right_leaf(index);

    if (buddy.longest[left] >= n) {
        index = left;
    } else if (buddy.longest[right] >= n) {
        offset += level_size;
        index = right;
    } else {
        return NULL; // 无可用块
    }
}

// 3. 标记分配并更新父节点
buddy.longest[index] = 0;
int parent_index = parent(index);
while (index > 0) {
    buddy.longest[parent_index] = MAX(buddy.longest[left_leaf(parent_index)],
                                     buddy.longest[right_leaf(parent_index)]);
    index = parent_index;
    parent_index = parent(index);
}
```

**时间复杂度**：O(log n)，n为总页数

### 3.3 内存释放算法 (`buddy_free_pages`)

```c
// 1. 计算释放块偏移并验证
size_t offset = base - buddy.first_page;
assert((offset + n) <= buddy.size);

// 2. 重置页状态并标记空闲
for (size_t i = 0; i < n; i++) {
    base[i].flags = 0;
    set_page_ref(&base[i], 0);
}
SetPageProperty(base);
list_add(&free_list, &base->page_link);
nr_free += n;

// 3. 更新二叉树并尝试合并
int index = offset + buddy.size - 1;
buddy.longest[index] = n;

while (index > 0) {
    int parent_index = parent(index);
    int l = left_leaf(parent_index);
    int r = right_leaf(parent_index);

    if (buddy.longest[l] == buddy.longest[r] && is_power_of_2(buddy.longest[l])) {
        buddy.longest[parent_index] = buddy.longest[l] + buddy.longest[r];
    } else {
        buddy.longest[parent_index] = MAX(buddy.longest[l], buddy.longest[r]);
    }
    index = parent_index;
}
```

**时间复杂度**：O(log n)，n为总页数

## 4. buddy_pmm内存结构

```
+-------------------+ <-- 物理内存起始
| 预留页区域        |   // 存储longest二叉树数组
| (reserve_count页) |
+-------------------+ <-- first_page
| 可管理内存区域    |   // 大小为buddy.size页（2的幂）
| ┌───────────────┐ |
| │ 块大小=8页     │ |
| ├───────┬───────┤ |
| │ 4页   │ 4页   │ |
| ├─┬─┬─┬─┼─┬─┬─┬─┤ |
| │1│1│1│1│1│1│1│1│ |  // 叶子节点（1页）
| └─┴─┴─┴─┴─┴─┴─┴─┘ |
+-------------------+
| 未使用保留区域    |   // 初始化时调整为2的幂后剩余的页
+-------------------+
```

<!-- ### 4.2 二叉树与物理页映射
```
longest数组索引: 0   1   2   3   4   5   6   7   8   9  10  11  12  13  14
树结构层次:       根 ├──左──┼──左──┼──左
                   └──右──┼──左
                          └──右
物理页映射:                页0 页1 页2 页3 页4 页5 页6 页7
``` -->

## 5. 测试用例设计

### 5.1 测试架构

```
buddy_pmm测试套件
├── 功能正确性测试
│   ├── 基本分配释放
│   ├── 块分裂机制
│   ├── 伙伴合并机制
│   └── 边界条件处理
├── 性能测试
│   ├── 分配/释放效率
│   ├── 碎片率分析
│   └── 大规模操作稳定性
└── 完整性测试
    ├── 二叉树状态一致性
    ├── 内存泄漏检测
    └── 异常处理验证
```

### 5.2 详细测试用例

#### 测试用例 1：基本分配释放功能
```c
/**
 * 测试目的：验证基本的页分配和释放功能
 * 测试步骤：
 * 1. 分配1页内存
 * 2. 验证分配成功且指针有效
 * 3. 释放分配的页
 * 4. 验证内存状态恢复
 * 预期结果：分配释放正常，无内存泄漏
 */
void test_basic_alloc_free() {
    size_t initial_free = buddy_nr_free_pages();

    struct Page *p = buddy_alloc_pages(1);
    assert(p != NULL);
    assert(buddy_nr_free_pages() == initial_free - 1);

    buddy_free_pages(p, 1);
    assert(buddy_nr_free_pages() == initial_free);
    cprintf("测试1通过: 基本分配释放正常\n");
}
```

#### 测试用例 2：块分裂机制验证
```c
/**
 * 测试目的：验证块自动分裂功能
 * 测试步骤：
 * 1. 分配3页（应自动分裂为4页块）
 * 2. 验证分配成功
 * 3. 检查二叉树状态是否正确更新
 * 预期结果：大 block 正确分裂为小 block
 */
void test_block_splitting() {
    struct Page *p3 = buddy_alloc_pages(3);
    assert(p3 != NULL);

    // 验证实际分配了4页（2的幂）
    struct Page *p1 = buddy_alloc_pages(1);
    assert(p1 != NULL);

    buddy_free_pages(p3, 4);
    buddy_free_pages(p1, 1);
    cprintf("测试2通过: 块分裂机制正常\n");
}
```

#### 测试用例 3：伙伴合并机制验证
```c
/**
 * 测试目的：验证伙伴块自动合并功能
 * 测试步骤：
 * 1. 分配两个2页块
 * 2. 释放这两个块
 * 3. 尝试分配一个4页块
 * 预期结果：两个相邻块合并为一个4页块
 */
void test_block_merging() {
    struct Page *a = buddy_alloc_pages(2);
    struct Page *b = buddy_alloc_pages(2);
    assert(a != NULL && b != NULL);

    buddy_free_pages(a, 2);
    buddy_free_pages(b, 2);

    // 验证能否合并为4页块
    struct Page *merged = buddy_alloc_pages(4);
    assert(merged != NULL);

    buddy_free_pages(merged, 4);
    cprintf("测试3通过: 伙伴合并机制正常\n");
}
```

#### 测试用例 4：碎片化恢复验证
```c
/**
 * 测试目的：验证碎片化后内存能否完全恢复
 * 测试步骤：
 * 1. 分配不同大小的块制造碎片
 * 2. 按相反顺序释放所有块
 * 3. 验证能否分配最大块
 * 预期结果：内存完全合并，可分配最大块
 */
void test_fragmentation_recovery() {
    size_t max_size = buddy.size;
    struct Page *x1 = buddy_alloc_pages(1);
    struct Page *x2 = buddy_alloc_pages(2);
    struct Page *x3 = buddy_alloc_pages(1);
    assert(x1 && x2 && x3);

    // 按相反顺序释放以确保合并
    buddy_free_pages(x3, 1);
    buddy_free_pages(x2, 2);
    buddy_free_pages(x1, 1);

    // 验证能否分配最大块
    struct Page *max_block = buddy_alloc_pages(max_size);
    assert(max_block != NULL);

    buddy_free_pages(max_block, max_size);
    cprintf("测试4通过: 碎片化后恢复正常\n");
}
```

#### 测试用例 5：边界条件测试
```c
/**
 * 测试目的：验证边界条件处理
 * 测试步骤：
 * 1. 分配0页（应失败）
 * 2. 分配超过总页数的内存（应失败）
 * 3. 分配正好等于总页数的内存
 * 4. 释放空指针（应安全处理）
 * 预期结果：边界情况处理正确，不崩溃
 */
void test_edge_cases() {
    // 测试0页分配
    assert(buddy_alloc_pages(0) == NULL);

    // 测试超量分配
    assert(buddy_alloc_pages(buddy.size + 1) == NULL);

    // 测试最大块分配
    struct Page *max = buddy_alloc_pages(buddy.size);
    assert(max != NULL);
    buddy_free_pages(max, buddy.size);

    // 测试空指针释放
    buddy_free_pages(NULL, 1); // 应无崩溃

    cprintf("测试5通过: 边界条件处理正常\n");
}
```

## 6. 测试辅助函数

### 6.1 二叉树状态检查
```c
// 验证二叉树状态一致性
static int check_tree_consistency() {
    // 检查所有父节点是否正确反映子节点最大值
    for (int i = 0; i < buddy.size - 1; i++) {
        int left = left_leaf(i);
        int right = right_leaf(i);
        if (buddy.longest[i] != MAX(buddy.longest[left], buddy.longest[right])) {
            return -1; // 父节点值不正确
        }
    }
    return 0; // 状态一致
}
```

### 6.2 内存状态输出
```c
// 打印当前空闲块状态
static void dump_free_blocks() {
    cprintf("当前空闲块状态: \n");
    cprintf("总空闲页数: %u\n", buddy_nr_free_pages());
    cprintf("最大空闲块大小: %u\n", buddy.longest[0]);
}
```

## 7. 测试执行策略

### 7.1 测试顺序
1. **基础功能测试** → 验证核心分配释放逻辑
2. **算法特性测试** → 验证分裂与合并机制
3. **边界条件测试** → 验证异常情况处理
4. **压力测试** → 验证大规模操作稳定性
5. **一致性测试** → 验证内部状态正确性

### 7.2 测试环境要求
- 至少16页可用内存（满足合并测试需求）
- 可输出调试信息的控制台
- 基本的断言机制支持

## 8. 预期测试结果

### 8.1 功能正确性
- 所有有效分配请求返回连续物理页
- 释放操作正确更新二叉树状态
- 伙伴块自动合并功能正常
- 碎片化内存可完全恢复

### 8.2 性能指标
- 分配/释放操作时间复杂度为O(log n)
- 内存利用率较高，基本无外部碎片
- 大规模操作无性能退化

### 8.3 稳定性保证
- 长期运行无内存泄漏
- 边界情况处理安全
- 内部状态始终保持一致

## 9. 总结

buddy_pmm内存分配器通过基于2的幂次方块的分裂与合并机制，实现了高效的物理内存管理。其核心优势在于：

1. **低碎片特性**：通过伙伴合并机制有效减少外部碎片
2. **高效操作**：O(log n)的分配释放时间复杂度
3. **实现简单**：基于完全二叉树的结构易于理解和实现
4. **连续内存保证**：始终分配物理连续的内存块

测试结果表明，该buddy_pmm实现正确处理了各种分配释放场景，包括块分裂、伙伴合并和碎片化恢复等关键功能，能够满足操作系统对物理内存管理的基本需求。


# 四、SLUB 分配器设计与测试文档

## 1. 概述

### 1.1 设计目标
SLUB 分配器是一个高效的对象级内存分配器，专门用于管理小内存对象（≤128字节）。它采用两层架构设计，在性能和内存利用率之间取得平衡。

### 1.2 核心特性
- **固定大小缓存**：预定义 16B、32B、64B、128B 四种对象大小
- **零外部碎片**：相同大小对象集中管理
- **O(1) 时间复杂度**：分配和释放操作
- **自动内存回收**：Slab 完全空闲时立即释放物理页
- **高缓存局部性**：同一 Slab 内对象物理相邻

## 2. 架构设计

### 2.1 两层架构

#### 底层：页级分配器
```c
// 复用最佳适配页分配器
extern const struct pmm_manager best_fit_pmm_manager;
#define page_alloc() best_fit_pmm_manager.alloc_pages(1)
#define page_free(page) best_fit_pmm_manager.free_pages(page, 1)
```
**职责**：
- 以页为单位管理物理内存
- 为 SLUB 提供底层内存支持
- 处理大块内存分配

#### 上层：对象级分配器
```c
static void *slub_alloc(size_t size);
static void slub_free(void *ptr);
```
**职责**：
- 细粒度管理小对象（16B-128B）
- 维护空闲对象链表
- 管理 Slab 状态转换

### 2.2 数据结构关系

```
kmem_cache_t (缓存)
├── slabs_full      → slab_t → slab_t → ...    // 满 Slab 链表
├── slabs_partial   → slab_t → slab_t → ...    // 部分满 Slab 链表  
├── slabs_free      → slab_t → slab_t → ...    // 空 Slab 链表
└── obj_size = 16/32/64/128

slab_t (内存页)
├── free_list → obj_metadata → obj_metadata → ...  // 空闲对象链表
├── num_objs = 页内对象数量
└── free_objs = 当前空闲对象数
```

## 3. 核心算法

### 3.1 对象分配算法 (`slub_alloc`)

```c
// 1. 缓存选择：向上取整到最近的缓存大小
for (int i = 0; i < 4; i++) {
    if (obj_sizes[i] >= size) {
        cache = &caches[i];
        break;
    }
}

// 2. Slab 选择优先级：部分满 → 空 → 新建
if (!list_empty(&cache->slabs_partial)) {
    // 优先使用部分满 Slab（缓存热点）
} else if (!list_empty(&cache->slabs_free)) {
    // 使用空 Slab，状态转移到部分满
} else {
    // 创建新 Slab
    slab = slab_create(cache);
}

// 3. 对象分配：从空闲链表头部取出
obj_metadata_t *meta = slab->free_list;
slab->free_list = meta->next;
slab->free_objs--;

// 4. 状态检查：Slab 是否变满
if (slab->free_objs == 0) {
    // 移到满链表
}
```

**时间复杂度**：O(1)

### 3.2 对象释放算法 (`slub_free`)

```c
// 1. 定位对象元数据（ptr - 1）
obj_metadata_t *meta = (obj_metadata_t *)ptr - 1;

// 2. 放回空闲链表头部
meta->next = slab->free_list;
slab->free_list = meta;
slab->free_objs++;

// 3. 状态转移检查
if (slab->free_objs == 1) {
    // 从满变部分满
} else if (slab->free_objs == slab->num_objs) {
    // Slab 完全空闲，释放物理页
    page_free(slab->page);
}
```

**时间复杂度**：O(1)

### 3.3 Slab 创建算法 (`slab_create`)

```c
// 1. 分配物理页
struct Page *page = page_alloc();

// 2. 计算页内对象容量
size_t slab_meta_size = sizeof(slab_t);
size_t remaining = PGSIZE - slab_meta_size;
slab->num_objs = remaining / (cache->obj_size + sizeof(obj_metadata_t));

// 3. 初始化空闲链表（头插法）
for (size_t i = 0; i < slab->num_objs; i++) {
    obj_metadata_t *meta = (obj_start + i * total_size);
    meta->next = slab->free_list;
    slab->free_list = meta;
}
```

## 4. 内存布局

### 4.1 Slab 内存结构
```
+-------------------+ <-- Slab 开始 (虚拟地址)
| slab_t 元数据     |   // 56字节 (7个字段 × 8字节)
|   - slab_link     |   // 链表节点
|   - page          |   // 指向物理页
|   - obj_size      |   // 对象大小
|   - num_objs      |   // 总对象数  
|   - free_objs     |   // 空闲对象数
|   - free_list     |   // 空闲链表头
+-------------------+
| obj_metadata[0]   |   // 8字节 (next指针)
| 对象数据[0]       |   // obj_size 字节
+-------------------+
| obj_metadata[1]   |
| 对象数据[1]       |
+-------------------+
| ...               |
+-------------------+
| obj_metadata[N-1] |
| 对象数据[N-1]     |
+-------------------+
```

### 4.2 对象大小计算示例
- **16B 缓存**：`(4096 - 56) / (16 + 8) ≈ 168` 个对象
- **32B 缓存**：`(4096 - 56) / (32 + 8) ≈ 101` 个对象  
- **64B 缓存**：`(4096 - 56) / (64 + 8) ≈ 56` 个对象
- **128B 缓存**：`(4096 - 56) / (128 + 8) ≈ 30` 个对象

## 5. 测试用例设计

### 5.1 测试架构

```
SLUB 测试套件
├── 功能正确性测试
│   ├── 基本分配释放
│   ├── 数据完整性  
│   ├── 对象复用
│   └── 多缓存协同
├── 边界情况测试
│   ├── 大小适配
│   ├── 内存耗尽
│   └── 无效指针
├── 性能测试
│   ├── 分配速度
│   ├── 内存利用率
│   └── 碎片分析
└── 稳定性测试
    ├── 长期运行
    ├── 并发访问
    └── 内存泄漏
```

### 5.2 详细测试用例

#### 测试用例 1：基本功能验证
```c
/**
 * 测试目的：验证最基本的分配和释放功能
 * 测试步骤：
 * 1. 分配16字节对象
 * 2. 验证分配成功
 * 3. 释放对象
 * 4. 验证内存状态
 * 预期结果：分配成功，释放后内存完全回收
 */
void test_basic_functionality(void) {
    size_t initial_pages = slub_nr_free_pages();

    void *obj = slub_alloc(16);
    assert(obj != NULL);

    slub_free(obj);

    size_t final_pages = slub_nr_free_pages();
    assert(initial_pages == final_pages);
}
```

#### 测试用例 2：大小适配验证
```c
/**
 * 测试目的：验证不同大小对象分配到正确的缓存
 * 测试步骤：
 * 1. 分配10B、20B、40B、80B对象
 * 2. 验证它们使用16B、32B、64B、128B缓存
 * 3. 验证同一缓存对象共享Slab
 * 预期结果：大小适配正确，缓存隔离良好
 */
void test_size_alignment(void) {
    void *obj10 = slub_alloc(10);   // 应使用16B缓存
    void *obj15 = slub_alloc(15);   // 应使用16B缓存
    void *obj20 = slub_alloc(20);   // 应使用32B缓存
    void *obj40 = slub_alloc(40);   // 应使用64B缓存

    // 验证缓存选择正确
    assert(slab_of(obj10)->obj_size == 16);
    assert(slab_of(obj20)->obj_size == 32);

    // 验证同一缓存对象在同一Slab
    assert(slab_of(obj10) == slab_of(obj15));

    // 清理
    slub_free(obj10); slub_free(obj15);
    slub_free(obj20); slub_free(obj40);
}
```

#### 测试用例 3：Slab 状态转换验证
```c
/**
 * 测试目的：验证Slab在empty/partial/full状态间正确转换
 * 测试步骤：
 * 1. 分配对象直到Slab变满
 * 2. 释放对象观察状态转换
 * 3. 验证链表操作正确
 * 预期结果：状态转换符合预期，链表维护正确
 */
void test_slab_state_transitions(void) {
    kmem_cache_t *cache = &caches[0]; // 16B缓存
    slab_t *slab = list_first_entry(&cache->slabs_partial, slab_t, slab_link);
    size_t obj_per_slab = slab->num_objs;

    // 分配所有对象使Slab变满
    void **objects = slub_alloc(sizeof(void*) * obj_per_slab);
    for (size_t i = 0; i < obj_per_slab; i++) {
        objects[i] = slub_alloc(16);
    }

    // 验证进入full状态
    assert(!list_empty(&cache->slabs_full));
    assert(slab->free_objs == 0);

    // 释放一个对象，进入partial状态
    slub_free(objects[0]);
    assert(!list_empty(&cache->slabs_partial));
    assert(slab->free_objs == 1);

    // 释放所有对象，进入free状态并释放页面
    for (size_t i = 1; i < obj_per_slab; i++) {
        slub_free(objects[i]);
    }
    assert(list_empty(&cache->slabs_full));
    assert(list_empty(&cache->slabs_partial));

    slub_free(objects);
}
```

#### 测试用例 4：内存泄漏检测
```c
/**
 * 测试目的：验证没有内存泄漏
 * 测试步骤：
 * 1. 记录初始内存状态
 * 2. 执行复杂分配模式
 * 3. 释放所有对象
 * 4. 验证内存状态恢复
 * 预期结果：内存完全回收，零泄漏
 */
void test_memory_leak_detection(void) {
    size_t initial_pages = slub_nr_free_pages();

    // 复杂分配模式
    void *pattern[100];
    for (int i = 0; i < 100; i++) {
        size_t size = 16 + (i % 4) * 16; // 使用所有缓存
        pattern[i] = slub_alloc(size);
        memset(pattern[i], i & 0xFF, size); // 写入数据
    }

    // 部分释放
    for (int i = 0; i < 100; i += 2) {
        slub_free(pattern[i]);
        pattern[i] = NULL;
    }

    // 重新分配
    for (int i = 0; i < 100; i += 2) {
        pattern[i] = slub_alloc(16 + (i % 4) * 16);
    }

    // 最终清理
    for (int i = 0; i < 100; i++) {
        if (pattern[i]) slub_free(pattern[i]);
    }

    size_t final_pages = slub_nr_free_pages();
    assert(initial_pages == final_pages);
}
```

#### 测试用例 5：边界情况处理
```c
/**
 * 测试目的：验证边界情况的正确处理
 * 测试步骤：
 * 1. 分配0字节对象
 * 2. 分配精确匹配大小的对象
 * 3. 分配超过最大缓存的对象
 * 4. 释放空指针
 * 预期结果：边界情况处理合理，不崩溃
 */
void test_edge_cases(void) {
    // 0字节分配
    void *obj0 = slub_alloc(0);
    if (obj0) slub_free(obj0);

    // 精确大小分配
    void *obj16 = slub_alloc(16);
    assert(obj16 != NULL);
    slub_free(obj16);

    // 过大对象分配
    void *obj_big = slub_alloc(200);
    assert(obj_big == NULL);

    // 空指针释放
    slub_free(NULL); // 应该不崩溃
}
```

#### 测试用例 6：性能基准测试
```c
/**
 * 测试目的：验证分配性能
 * 测试步骤：
 * 1. 测量分配/释放操作耗时
 * 2. 验证O(1)时间复杂度
 * 3. 比较与页分配器的性能差异
 * 预期结果：分配释放操作在常数时间内完成
 */
void test_performance_benchmark(void) {
    const int ITERATIONS = 10000;
    void *objects[1000];

    // 分配性能测试
    uint64_t start_time = get_ticks();
    for (int i = 0; i < ITERATIONS; i++) {
        objects[i % 1000] = slub_alloc(32);
    }
    uint64_t alloc_time = get_ticks() - start_time;

    // 释放性能测试
    start_time = get_ticks();
    for (int i = 0; i < ITERATIONS; i++) {
        slub_free(objects[i % 1000]);
    }
    uint64_t free_time = get_ticks() - start_time;

    cprintf("SLUB Performance: alloc=%lu ticks/op, free=%lu ticks/op\n", 
            alloc_time / ITERATIONS, free_time / ITERATIONS);
}
```

## 6. 测试辅助函数

### 6.1 调试输出函数
```c
// 输出缓存状态信息
static void dump_cache_status(kmem_cache_t *cache) {
    cprintf("Cache %dB: full=%d, partial=%d, free=%d\n", 
            cache->obj_size,
            list_size(&cache->slabs_full),
            list_size(&cache->slabs_partial), 
            list_size(&cache->slabs_free));
}

// 输出Slab详细信息
static void dump_slab_status(slab_t *slab) {
    cprintf("Slab %p: objs=%d/%d, free_list=%p\n",
            slab, slab->free_objs, slab->num_objs, slab->free_list);
}
```

### 6.2 完整性检查函数
```c
// 验证SLUB分配器内部状态一致性
static int slub_integrity_check(void) {
    for (int i = 0; i < 4; i++) {
        kmem_cache_t *cache = &caches[i];

        // 检查链表完整性
        if (!list_check(&cache->slabs_full) ||
            !list_check(&cache->slabs_partial) || 
            !list_check(&cache->slabs_free)) {
            return -1;
        }

        // 检查Slab对象计数
        list_entry_t *le;
        list_for_each(le, &cache->slabs_full) {
            slab_t *slab = le2slab(le, slab_link);
            if (slab->free_objs != 0) return -2;
        }

        list_for_each(le, &cache->slabs_free) {
            slab_t *slab = le2slab(le, slab_link);
            if (slab->free_objs != slab->num_objs) return -3;
        }
    }
    return 0; // 完整性检查通过
}
```

## 7. 测试执行策略

### 7.1 测试顺序
1. **基础功能测试** → 确保核心分配释放功能正常
2. **边界情况测试** → 验证鲁棒性和错误处理
3. **性能基准测试** → 验证时间复杂度和性能
4. **内存完整性测试** → 验证内部数据结构一致性
5. **长期稳定性测试** → 验证无内存泄漏和状态保持

### 7.2 测试环境要求
- 足够内存空间运行压力测试
- 可控制的测试模式避免影响系统稳定性
- 详细的内存状态监控和调试输出

## 8. 预期测试结果

### 8.1 功能正确性
- 所有分配请求返回有效指针
- 释放后内存完全回收
- 对象复用正确实现
- 多缓存协同工作正常

### 8.2 性能指标  
- 分配/释放操作 O(1) 时间复杂度
- 内存利用率 >90%（内部碎片可控）
- 零外部碎片

### 8.3 稳定性保证
- 长期运行无内存泄漏
- 并发访问数据一致性
- 边界情况安全处理

## 9. 总结

本测试套件全面覆盖了 SLUB 分配器的所有关键功能点和边界情况，通过系统化的测试验证确保分配器在生产环境中的正确性、性能和稳定性。测试设计充分考虑了实际使用场景，能够有效发现和预防潜在问题。

通过这套测试，我们可以确信 SLUB 分配器：
1. 正确实现了小内存高效分配
2. 具有良好的内存利用率
3. 提供稳定的运行时性能
4. 具备生产环境所需的可靠性










# 五、思考题：操作系统获取可用物理内存范围的方法

## 1、问题背景

在 RISC-V 架构下，操作系统在启动初期需要完成物理内存管理初始化工作。在本次实验中，`kern_init()` 会调用 `pmm_init()` 来建立物理页管理结构，而在执行该函数之前，内核必须先明确当前硬件的**可用物理内存范围**。

然而，RISC-V 处理器本身并不会提供直接的“内存大小寄存器”或“自动探测机制”，因此 **操作系统无法直接得知可用物理内存的起止地址**，必须依赖其他途径来获得此信息。

---

## 2、RISC-V 平台上获取物理内存范围的主要方法

### (1). 通过设备树（Device Tree, DTB）获取（推荐方式）

RISC-V 平台通常采用 **设备树（Flattened Device Tree, 简称 DTB）** 描述硬件资源，包括 CPU、内存、外设等信息。
系统启动流程一般为：

1. 硬件或仿真环境（如 QEMU）首先加载 **引导程序（如 OpenSBI 或 bbl）**；
2. 引导程序会在启动内核前，将一份 **DTB 的物理地址** 传递给内核（通常放在寄存器 `a1` 中）；
3. 内核启动后，在 `entry.S` 中从寄存器中获取 DTB 的地址；
4. 内核通过解析 DTB 文件中的 `memory` 节点，读取物理内存的起始地址与大小，从而确定系统可用物理内存范围。

**示例（DTB 中的内存节点）**：

```dts
memory@80000000 {
    device_type = "memory";
    reg = <0x0 0x80000000 0x0 0x08000000>; // base=0x80000000, size=128MB
};
```

在内核解析该节点后，即可得知：
可用物理内存起始地址为 `0x80000000`，大小为 `0x08000000`（即 128MB）。

这种方式安全、标准化，也是 **RISC-V 架构下推荐的唯一正确做法**。
Linux、ucore 等系统均采用此机制。

---

### (2). 由引导程序（Bootloader）直接传递内存信息

在某些实验环境中（如修改版的 ucore），可以让引导程序在进入内核前**主动将内存范围信息写入寄存器或内存**，然后内核在 `kern_entry` 中读取。
例如，Bootloader 可在寄存器 `a0` 中放入内存起始地址，在 `a1` 中放入内存大小。

```assembly
# bootloader 中
li a0, 0x80000000    # memory base
li a1, 0x08000000    # memory size = 128MB
call kern_entry
```

内核即可在 `kern_entry` 或 `kern_init` 中读取这两个参数，完成物理内存管理初始化。
这种方法逻辑清晰，适合教学实验使用，但实际系统仍然推荐使用 DTB。

---

### (3). 固定配置法（实验性方法）

在硬件配置固定的情况下（例如 QEMU 虚拟机中内存大小固定为 128MB），也可以直接在内核中定义常量：

```c
#define PHY_MEM_BASE 0x80000000
#define PHY_MEM_END  0x88000000
```

在这种方式下，内核无需探测或解析，只需按照固定范围建立页管理结构即可。
该方法实现最简单，但可移植性差，无法适应不同硬件环境。

---



<!--  -->

## 3、结论

- 在 RISC-V 平台上，如果操作系统无法提前知道可用物理内存范围，最常用的做法是通过 **引导程序传递设备树（DTB）** 的方式获取内存信息。
- 内核在启动阶段解析设备树中的 `memory` 节点，即可得到物理内存的起始地址和大小，从而完成物理内存管理初始化。这是目前 RISC-V 平台上最安全、标准且通用的方案。

---











# 五、重要知识点


## 1、虚拟地址与物理地址的映射
在设定satp，启用mmu之前，指令执行都在物理地址上执行。
但是ELF/链接器把 kern_entry 链接到内核的虚拟基址（VMA），所以符号表里是像 0xffffffffc0200000 这样的“虚拟地址”。
我们此时观察虚拟地址，是没有任何指令的：
```bash
(gdb) disassemble /r kern_entry  
Dump of assembler code for function kern_entry:
   0xffffffffc0200000 <+0>:     0000                    unimp
   0xffffffffc0200002 <+2>:     0000                    unimp
   0xffffffffc0200004 <+4>:     0000                    unimp
   0xffffffffc0200006 <+6>:     0000                    unimp
   0xffffffffc0200008 <+8>:     0000                    unimp
   0xffffffffc020000a <+10>:    0000                    unimp
```


在不开启 MMU 时用 PC 相对指令（auipc/addi）访问数据、并把需要的虚拟地址经由已知的 VA↔PA 偏移算成物理（写入 satp 前都做了转换），然后写入 satp 启用页表。
启用后才按虚拟地址继续执行。

我们接下来观察satp被设置的前后发生的变化
```bash
(gdb) break * 0x80200030

(gdb) x/3i $pc
=> 0x80200030:  or      t0,t0,t1
   0x80200034:  csrw    satp,t0
   0x80200038:  sfence.vma
```


此时，在`0x80200038`执行后已经成功启用mmu，此时开始使用虚拟内存，无法通过物理地址进行访问。
```bash
(gdb) x/5i $pc
=> 0x8020003c:  Cannot access memory at address 0x8020003c
(gdb) x/5i 0xffffffffc020003c
   0xffffffffc020003c <kern_entry+60>:  lui     sp,0xc0205
   0xffffffffc0200040 <kern_entry+64>:  lui     t0,0xc0200
   0xffffffffc0200044 <kern_entry+68>:  addi    t0,t0,214
   0xffffffffc0200048 <kern_entry+72>:  jr      t0
```


接下来，我们具体分析一下映射过程。
使用first_fit_pmm时boot_page_table_sv39所在的虚拟地址：
```bash
(gdb)  p/x (void*)&boot_page_table_sv39
$1 = 0xffffffffc0205000
```
其对应的物理地址为`0x0000000080205000`，将其右移12位后作为PPN存入satp中，后面能够通过satp算出三级基页表的起始物理地址

对于这个页表，我们已经写入了一个页表项
```asm
boot_page_table_sv39:
    # 0xffffffff_c0000000 map to 0x80000000 (1G)
    # 前 511 个页表项均设置为 0 ，因此 V=0 ，意味着是空的(unmapped)
    .zero 8 * 511
    # 设置最后一个页表项，PPN=0x80000，标志位 VRWXAD 均为 1
    .quad (0x80000 << 10) | 0xcf # VRWXAD

    .global boot_hartid
```
我们要映射的虚拟地址的为`0xffffffff_c0000000`,取[38:30]为511，所以我们这里向最后一个页表项中添加对应的物理地址PPN。
我们将这个页表项所指向的页直接当做一个叶子结点，不再有接下来的次级页表，我们的虚拟地址此时还有30位没有使用，所以这是一个1GiB的大大页，30位来提供页内偏移。<br>
但是，我们在取PPN存入PTE时，都只会将地址右移12位（此时为默认的4kib大小的页），我们如果使用1GiB的大大页，应该需要再右移18位，但是在这个阶段不会进行这样的处理。
我们只有在访问页表项获取物理地址时才会根据当前页表项所指向的页的大小来获取对应的地址位数，这些都是硬件在翻译过程中的操作。<br>
不过写 PTE 时有对齐/零位的要求,如果把某级 PTE 当作叶子来做大页映射，那么 PTE 保存的 PPN 的低若干位必须为 0，以保证物理基址满足该大页的对齐要求（比如 1GiB 大页要求 PPN 的低 18 位为 0，2MiB 大页要求低 9 位为 0）。这是在建立页表时需要保证的条件。

## 2. 多级页表（SV39） 

页表必须以 4 KiB 对齐（页表物理地址低 12 位为 0），每个页表占用一页（4096 字节）。
SV39 使用 三级页表（三层索引），每层索引 9 位（0–511，共 512 项），每个 PTE 8 字节。
页面大小（取决于叶子 PTE 所在层级）：
级别 0（leaf 在 level 0）→ 4 KiB 页面（2^12）<br>
级别 1（leaf 在 level 1）→ 2 MiB 页面（2^(12+9)）<br>
级别 2（leaf 在 level 2）→ 1 GiB 页面（2^(12+9*2)）<br>

虚拟地址位划分（SV39）

对于 39 位虚拟地址（VA），位域如下：

VA[38:0] = VPN[2] (bits 38:30) | VPN[1] (bits 29:21) | VPN[0] (bits 20:12) | offset (bits 11:0)

进行逐级索引，通过页表项找到页的物理地址，页表相当于只是一个中间层。
